{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fda3492d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import time\n",
    "\n",
    "try:\n",
    "    import PyPDF2\n",
    "except ModuleNotFoundError:\n",
    "    !pip install PyPDF2\n",
    "    \n",
    "try:\n",
    "    import openai\n",
    "except ModuleNotFoundError:\n",
    "    !pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e9b335b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Write paper link   \n",
    "url=\"https://arxiv.org/pdf/1912.04958.pdf\"\n",
    "\n",
    "#Choose the preferred language\n",
    "lang=\"English\"\n",
    "\n",
    "#Give a name to your summary (optional)\n",
    "article_name=\"paper.pdf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8fd543dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "!curl -s -o $article_name $url\n",
    "# Set the string that will contain the summary     \n",
    "pdf_summary_text = \"\"\n",
    "# Read the PDF file using PyPDF2\n",
    "pdf_file = open(article_name, 'rb')\n",
    "pdf_reader = PyPDF2.PdfReader(pdf_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "586da2b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask(demand):\n",
    "    # Call the OpenAI API to generate a response to the 'demand' parameter using a GPT-3.5 model called \"gpt-3.5-turbo\".\n",
    "    response = openai.ChatCompletion.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[\n",
    "        # Set the context by sending a system message to the model informing the user that they are a helpful research assistant.\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful research assistant.\"},\n",
    "        # Send the 'demand' parameter as a user message to the model.\n",
    "        {\"role\": \"user\", \"content\": demand},\n",
    "        ],\n",
    "    )\n",
    "    # Return the generated response as a string. The content of the first message choice returned by the API response.\n",
    "    return response[\"choices\"][0][\"message\"][\"content\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b5b47ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summarizing page 0\n",
      "Summarizing page 1\n",
      "Summarizing page 2\n",
      "Summarizing page 3\n",
      "Summarizing page 4\n",
      "Summarizing page 5\n",
      "Summarizing page 6\n"
     ]
    }
   ],
   "source": [
    "page_sums=[]\n",
    "\n",
    "# Loop through all the pages in the PDF file\n",
    "for page_num in range(len(pdf_reader.pages)):\n",
    "    # Extract the text from the page\n",
    "    page_text = pdf_reader.pages[page_num].extract_text().lower()\n",
    "\n",
    "    max_retries = 10\n",
    "    retries = 0\n",
    "    while retries < max_retries:\n",
    "        try:\n",
    "            demand = f\"Summarize this in {lang} : {page_text}\"\n",
    "            page_summary = ask(demand)\n",
    "            page_sums.append(page_summary)\n",
    "            print(\"Summarizing page \" + str(page_num))\n",
    "            break  # If the API call is successful, break the loop\n",
    "        except openai.errors.RateLimitError as e:\n",
    "            print(f\"Caught RateLimitError: {e}\")\n",
    "            retries += 1\n",
    "            if retries < max_retries:\n",
    "                print(f\"Waiting for 10 seconds before retrying. Retry attempt {retries}/{max_retries}.\")\n",
    "                time.sleep(10)\n",
    "            else:\n",
    "                print(f\"Reached maximum retries ({max_retries}). Exiting.\")\n",
    "                break\n",
    "    else:\n",
    "        # If the loop has finished and no successful API call was made, skip this iteration\n",
    "        continue\n",
    "\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e88441e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_summary_text='\\n'.join(page_sums)\n",
    "page_to_page_summary = article_name.replace(os.path.splitext(article_name)[1], \".ptp_summary.txt\")\n",
    "\n",
    "# Create the page summaries\n",
    "with open(page_to_page_summary, \"w+\", encoding=\"utf-8\") as file:\n",
    "    file.write(pdf_summary_text)\n",
    "print(pdf_summary_text)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4043c7de",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Give minimum words for your summary\n",
    "minimum_words=300\n",
    "\n",
    "ultimate_summary = \"\"\n",
    "page_limit = 5\n",
    "division=int(len(page_sums) / page_limit)\n",
    "\n",
    "if len(page_sums) > page_limit:\n",
    "    # divide the list into smaller parts\n",
    "    smaller_lists = [page_sums[i:i + page_limit] for i in range(0, len(page_sums), page_limit)]\n",
    "\n",
    "    # concatenate the items in each smaller list\n",
    "    concat_list = [''.join(smaller_list) for smaller_list in smaller_lists]\n",
    "\n",
    "    for i in concat_list:\n",
    "        first_summary = ' '.join(pdf_summary_text.split(' ')[:500])\n",
    "        \n",
    "        # Generate a summary for each smaller list and concatenate them\n",
    "        demand = f\"Create summary of this text in {lang} consisting maximum {minimum_words} words. {first_summary}\"\n",
    "        ultimate_summary_part = ask(demand)\n",
    "        ultimate_summary += ultimate_summary_part + \"\\n\"\n",
    "    \n",
    "    # Generate a final summary from the concatenated summaries    \n",
    "    demand = f\"Create summary of this text in {lang} from these page summaries. Calculate tokens left and use maximum tokens you can.   {ultimate_summary}\"\n",
    "    ultimate_summary_part = ask(demand)\n",
    "    ultimate_summary_file = article_name.replace(os.path.splitext(article_name)[1], \".summary.txt\")\n",
    "\n",
    "else:\n",
    "\n",
    "    first_summary = ' '.join(pdf_summary_text.split(' ')[:500])\n",
    "    demand = f\"Create a summary of this text in {lang}. The text must have minimum {minimum_words} words. Calculate tokens left and use maximum tokens you can. {first_summary}\"\n",
    "    ultimate_summary = ask(demand)\n",
    "    ultimate_summary_file = article_name.replace(os.path.splitext(article_name)[1], \".summary.txt\")\n",
    "    \n",
    "with open(ultimate_summary_file, \"w+\", encoding=\"utf-8\") as file2:\n",
    "    file2.write(ultimate_summary)\n",
    "\n",
    "print(ultimate_summary)\n",
    "file2.close()\n",
    "pdf_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeca88a3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
